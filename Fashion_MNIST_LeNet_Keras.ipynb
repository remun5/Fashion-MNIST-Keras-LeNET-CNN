{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNIST-LeNet-Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxNFhUv7wHDxq6Ly//4Yeb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remun5/Fashion-MNIST-Keras-LeNET-CNN/blob/master/Fashion_MNIST_LeNet_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otFKsoP-FU7v",
        "colab_type": "text"
      },
      "source": [
        "## **Fashion MNIST Dataset with Convolutional Neural Network:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLxLIAYPjidx",
        "colab_type": "text"
      },
      "source": [
        "In this project, we will again use the Fashion MNIST dataset and implement the LeNet-5 Convolutional Neural Network based learning. LetNet-5 architecture can found in the paper \"Gradient-Based Learning Applied to Document. Recognition. Yann LeCun, LÃ©eon Bottou, Yoshua Bengio, and Patrick Haffner\". The idea of this was to process handwriting. However, since Fashion MNIST dataset is also a low resolution MNIST like dataset, we will try to implement it and compare it to the previously implemented simple neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l84VtoQQFbMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Input, Conv2D, AveragePooling2D, Flatten, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfNiQMozM813",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpuqBWKcM_pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxsXM7bCNBgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_enc = np_utils.to_categorical(y_train)\n",
        "y_test_enc = np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2f0Lj5ZY3y1",
        "colab_type": "text"
      },
      "source": [
        "### **LeNet 5:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9WcAUiYNDyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LeNetCNN(input_shape):\n",
        "  X_input = Input(shape=input_shape)\n",
        "  X = Conv2D(filters=6, kernel_size=(5,5), activation='tanh')(X_input)\n",
        "  X = AveragePooling2D(pool_size = (2,2), strides=(2,2))(X)\n",
        "  X = Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='tanh')(X)\n",
        "  X = AveragePooling2D(pool_size=(2,2), strides=(2,2))(X)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(units=120, activation='tanh')(X)\n",
        "  X = Dense(units=84, activation='tanh')(X)\n",
        "  X = Dense(units=10, activation='softmax')(X)\n",
        "  model = Model(inputs = X_input, outputs = X, name='LeNet')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVbj7UUnDvOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_LeNet = LeNetCNN((28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-usZf_3cJxrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "172bd60a-3049-4186-e54d-d62467c956f0"
      },
      "source": [
        "print(mnist_LeNet.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"LeNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_7 (Average (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZ9cUH6SoFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_LeNet.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRy1y1XJSyts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c9397c27-3122-4ef9-9006-464509896f43"
      },
      "source": [
        "mnist_LeNet.fit(x = X_train, y = y_train_enc, epochs = 10, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2474 - accuracy: 0.9071\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.2353 - accuracy: 0.9119\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2335 - accuracy: 0.9121\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.2197 - accuracy: 0.9176\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.2138 - accuracy: 0.9199\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2078 - accuracy: 0.9216\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.2019 - accuracy: 0.9239\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.1957 - accuracy: 0.9271\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.1912 - accuracy: 0.9279\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.1860 - accuracy: 0.9299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb55b35a5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlLYAK9KS5BE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ad37c05b-8b11-4968-82b7-a7687ff8aa19"
      },
      "source": [
        "preds_train = mnist_LeNet.evaluate(x=X_train, y = y_train_enc)\n",
        "print('Training::')\n",
        "print (\"Loss = \" + str(preds_train[0]))\n",
        "print (\"Training Accuracy = \" + str(preds_train[1]))\n",
        "\n",
        "preds = mnist_LeNet.evaluate(x = X_test, y = y_test_enc)\n",
        "print('Testing::')\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1849 - accuracy: 0.9305\n",
            "Training::\n",
            "Loss = 0.18494786322116852\n",
            "Training Accuracy = 0.9305499792098999\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3070 - accuracy: 0.8939\n",
            "Testing::\n",
            "Loss = 0.30698275566101074\n",
            "Test Accuracy = 0.8938999772071838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fU0_CMqkYTl",
        "colab_type": "text"
      },
      "source": [
        "Here, as you can see the training and testing accuracies have improved from 91% training and 88% test accracies to 93% training and 89% test accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DCaaj6KkvQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}